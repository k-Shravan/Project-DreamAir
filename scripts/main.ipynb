{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cd264b0-27e0-4bdd-9baf-28d03e1b6e48",
   "metadata": {},
   "source": [
    "# Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d91a1bf7-6ccc-431d-a88e-7248c8fc57c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from datetime import datetime, timedelta\n",
    "from faker import Faker\n",
    "import os\n",
    "from geopy.distance import geodesic\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dda8552f-edfa-4f0f-90ec-2d48358ba462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrav\\Data_Analysis_Projects\\Big Projects\\Project Dream Air\\Datasets\n"
     ]
    }
   ],
   "source": [
    "%cd C:\\Users\\shrav\\Data_Analysis_Projects\\Big Projects\\Project Dream Air\\Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5492ac6-0e7a-4aa9-8b03-66fb2600a3a7",
   "metadata": {},
   "source": [
    "# Initialize Faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb7dd7b0-a69f-4fd0-8367-b32f0f233aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = Faker()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9289d9b6-1c16-435e-8acb-702de5054413",
   "metadata": {},
   "source": [
    "# roundup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c10c8f0-e48e-4118-8684-2c3ad2f76641",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roundup(x):\n",
    "    return math.ceil(x / 10.0) * 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c87926-d2d6-41d2-bad5-053ca3743375",
   "metadata": {},
   "source": [
    "# return_time_from_decimal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30f4dfdc-ef05-48fc-a42f-67bdedd1358e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_time_from_decimal(decimal_time: int):\n",
    "    '''\n",
    "    Returns a HH:MM:SS(seconds = 0) format time from a decimal format of HH.MM\n",
    "    :param decimal_time: time format of HH.MM\n",
    "    '''\n",
    "    f_hour = int(decimal_time)\n",
    "    f_minute = round((decimal_time - f_hour) * 60)\n",
    "    return f'{f_hour:02}:{f_minute:02}:00'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187f8f0e-ea35-49c7-ba94-edaa287e1f19",
   "metadata": {},
   "source": [
    "# routes_dict_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13cce364-dbbf-43f2-8ddd-f777d69d37db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def routes_dict_generator(input_file: str) -> dict:\n",
    "    \"\"\"Creates a dict {route_id: [price, travel_time]}\n",
    "    :param input_file: Must be in the format of (ID,Source,Destination,Price,Travel_time)\n",
    "    :return: {route_id: [price, travel_time]}\"\"\"\n",
    "    with open(input_file, encoding='utf-8', newline='') as routes_file:\n",
    "        routes_file.readline().strip('\\n\\r').split(',')\n",
    "        routes_reader = csv.reader(routes_file)\n",
    "        return {int(f_row[0]): f_row[3:] for f_row in routes_reader}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873f1040-be41-4384-99db-62e257293ad4",
   "metadata": {},
   "source": [
    "# aircraft_dict_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c926200-b0c6-46f6-b987-c4b6f3bbef6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aircraft_dict_generator(input_file: str) -> dict:\n",
    "    \"\"\"Creates a dict {aircraft_id: seats}\n",
    "    :param input_file: Must be in the format (aircraft_ID,aircraft_reg_no,aircraft_name,seats)\n",
    "    :return: {aircraft_id: seats}\"\"\"\n",
    "    with open(input_file, encoding='utf-8', newline='') as f_aircraft_file:\n",
    "        f_aircraft_file.readline().strip('\\n\\r').split(',')\n",
    "        aircraft_file_reader = csv.reader(f_aircraft_file)\n",
    "        return {int(f_row[0]): f_row[3] for f_row in aircraft_file_reader}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f37a327-9634-4aba-aeac-fc617901643d",
   "metadata": {},
   "source": [
    "# round_off_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "783ce2d5-13f7-4b2e-a30d-7865e7c6b5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_off_time(time_string: str):\n",
    "    '''\n",
    "    Returns a time string of \"%H:%M:%S\" where the minutes are rounded off to nearest (0, 15, 30, 45) min.\n",
    "    If minute part is over 45 then the next hour is returned.\n",
    "    \n",
    "    time_string: Time string in a format HH:MM:SS\n",
    "    \n",
    "    return Rounded off time string to the nearest (0, 15, 30, 45)\n",
    "    '''\n",
    "    time_obj = datetime.strptime(time_string, \"%H:%M:%S\")\n",
    "    available_minutes = (0, 15, 30, 45)\n",
    "    curr_minute = time_obj.minute\n",
    "    \n",
    "    if curr_minute in available_minutes:\n",
    "        return time_string\n",
    "\n",
    "    next_minute = min((minute for minute in available_minutes if minute > curr_minute), default=0)\n",
    "    \n",
    "    if next_minute == 0:\n",
    "        time_obj = time_obj.replace(minute=0, second=0) + timedelta(hours=1)\n",
    "    else:\n",
    "        time_obj = time_obj.replace(minute=next_minute, second=0)\n",
    "        \n",
    "    rounded_time = time_obj.strftime(\"%H:%M:%S\")\n",
    "\n",
    "    return rounded_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc18c4ad-d294-48fe-8e0f-c7b7e782d22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_aircraft_speed = 804.67  # km/hr\n",
    "da_price_multiplier = 4.5  # Rs/km\n",
    "da_airport_coordinates = {\n",
    "    \"DEL\": [(28.5562, 77.1000), 1],  # Indira Gandhi International Airport, Delhi\n",
    "    \"BOM\": [(19.0896, 72.8656), 1],  # Chhatrapati Shivaji Maharaj International Airport, Mumbai\n",
    "    \"BLR\": [(13.1986, 77.7066), 1],  # Kempegowda International Airport, Bangalore\n",
    "    \"HYD\": [(17.2288, 78.4292), 2],  # Rajiv Gandhi International Airport, Hyderabad\n",
    "    \"MAA\": [(12.9942, 80.1756), 2],  # Chennai International Airport, Chennai\n",
    "    \"CCU\": [(22.6559, 88.8425), 2],  # Netaji Subhas Chandra Bose International Airport, Kolkata\n",
    "    \"AMD\": [(23.1167, 72.6348), 2],  # Sardar Vallabhbhai Patel International Airport, Ahmedabad\n",
    "    \"COK\": [(10.1523, 76.4017), 3],  # Cochin International Airport, Kochi\n",
    "    \"GOI\": [(15.3809, 74.1487), 3],  # Dabolim Airport, Goa\n",
    "    \"LKO\": [(26.7606, 80.8890), 3],  # Chaudhary Charan Singh International Airport, Lucknow\n",
    "    \"GAU\": [(26.0334, 91.5880), 3],  # Lokpriya Gopinath Bordoloi International Airport, Guwahati\n",
    "    \"JAI\": [(26.8250, 75.8113), 4],  # Jaipur International Airport, Jaipur\n",
    "    \"BBI\": [(20.2985, 85.8189), 4],  # Biju Patnaik International Airport, Bhubaneswar\n",
    "    \"SXR\": [(33.9985, 74.1795), 4]   # Srinagar International Airport, Srinagar\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51460f1-64c5-4657-96e5-4a4f14f08e65",
   "metadata": {},
   "source": [
    "# create_routes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca8d10a3-e9f4-43b6-b55c-c243657b9a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_routes(output_file: str, airport_coordinates: dict, aircraft_speed: float, price_multiplier: float, convenience_fee: int) -> None:\n",
    "    \"\"\"\n",
    "    Uses airport_coordinates dict to calculate distance between the two airports, calculates time with the \n",
    "    aircraft_speed and calculates price using price_multiplier(rs/km) and an additional convinence fee.\n",
    "    o/p csv will be like this = (ID, Source, Destination, Distance, Travel_Time, Popularity, Price) The Source and Destination will be foriegn keys for the primary key of Airports table.\n",
    "    \n",
    "    :param output_file: File name where the csv data needs to go.\n",
    "    :param airport_coordinates: Dict with aiport IATA Code as keys and a list of coordinates and aiport popularity {IATA Code: [coordinates, popularity]}\n",
    "    :param aircraft_speed: Aircraft speed (Km/hr)\n",
    "    :param price_multiplier: Price per Km \n",
    "    :param convenience_fee: standard convenience_fee for the airline company\n",
    "\n",
    "    :rtype: None\n",
    "    \"\"\"\n",
    "    list_of_airports = list(airport_coordinates.keys())\n",
    "    no_of_airports = len(airport_coordinates) + 1\n",
    "    routes_list = []\n",
    "    \n",
    "    for source_index in range(1, no_of_airports):\n",
    "        for destination_index in range(source_index + 1, no_of_airports):\n",
    "            source = list_of_airports[source_index - 1]\n",
    "            destination = list_of_airports[destination_index - 1]\n",
    "            \n",
    "            distance = geodesic(airport_coordinates[source][0], airport_coordinates[destination][0]).kilometers\n",
    "            time = round((distance / aircraft_speed) + 0.5, 2)  # (0.5) take off and landing\n",
    "            \n",
    "            formatted_time = return_time_from_decimal(time)\n",
    "            rounded_off_time = round_off_time(formatted_time)\n",
    "\n",
    "            popularity = [airport_coordinates[source][1], airport_coordinates[destination][1]]\n",
    "            price = (distance * price_multiplier) + convenience_fee\n",
    "\n",
    "            if price < 2500:\n",
    "                price = 3000\n",
    "            elif price < 3500:\n",
    "                price = 3750\n",
    "\n",
    "            source_list = [source_index, destination_index, roundup(distance), rounded_off_time, sum(popularity) / 2, round(price, 2)]\n",
    "            destination_list = [destination_index, source_index, roundup(distance), rounded_off_time, sum(popularity) / 2, round(price, 2)]\n",
    "\n",
    "            routes_list.append(source_list)\n",
    "            routes_list.append(destination_list)\n",
    "\n",
    "    df = pd.DataFrame(routes_list, \n",
    "                      columns=[\"Source\", \"Destination\", \"Distance\", \"Travel_Time\", \"Popularity\", \"Price\"])\n",
    "    \n",
    "    df.sort_values(by=\"Popularity\", inplace=True)\n",
    "    df.drop(\"Popularity\", axis=1, inplace=True)\n",
    "    df.index = range(1, len(df) + 1)\n",
    "    df = df.rename_axis(index='ID')\n",
    "    df.to_csv(output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8255995e-eeab-433d-b6f6-6db7d3e3e8e9",
   "metadata": {},
   "source": [
    "# ticket_estimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08831a9a-562d-40d3-b01a-3b7c6b6006e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ticket_estimator(f_date: str, hike_list: list, tickets: int, f_year) -> int:\n",
    "    \"\"\" Generated a ticket estimate for the given f_year (for my use, intentionally used to depict a change in orders\n",
    "    to simulate a real dataset\"\"\"\n",
    "    year_adjustments = {2018: -5, 2020: -20}\n",
    "    tickets += year_adjustments.get(f_year, 0)\n",
    "\n",
    "    day_name = day_of_week_generator(f_date)\n",
    "\n",
    "    if f_date[5:] in hike_list:\n",
    "        if day_name not in (\"Thu\", \"Tue\", \"Wed\"):\n",
    "            return tickets\n",
    "        elif day_name == \"Wed\":\n",
    "            reduction = random.randint(10, 15)\n",
    "        else:\n",
    "            reduction = random.randint(5, 10)\n",
    "            \n",
    "    else:\n",
    "        if day_name in (\"Thu\", \"Tue\"):\n",
    "            reduction = random.randint(10, 20)\n",
    "        elif day_name == \"Wed\":\n",
    "            if f_year == 2018 or f_year == 2020:\n",
    "                reduction = random.randint(25, 35)\n",
    "            reduction = random.randint(10, 25)\n",
    "        else:\n",
    "            reduction = random.randint(0, 10)\n",
    "            \n",
    "    return int(tickets - tickets * (reduction/100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3092c826-10e1-414b-909c-c0ab5ee588cf",
   "metadata": {},
   "source": [
    "# generate_random_order_date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8edda85-3906-47e8-9b56-2e7a57ae2b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_order_date(date_time: str):\n",
    "    \"\"\"Creates a random datetime(randomly selected between 1 - 90 days, time is also random) before the given date\n",
    "    :param: str of format yyyy-mm-dd hh-mm-ss\n",
    "    :return: generates date in format of (yyyy-mm-dd hh-mm-ss) 90 days before the given date_time\"\"\"\n",
    "\n",
    "    random_days = random.randint(1, 90)\n",
    "    random_hours = random.randint(0, 23)\n",
    "    random_minutes = random.randint(0, 59)\n",
    "    random_seconds = random.randint(0, 59)\n",
    "\n",
    "    date_obj = datetime.strptime(date_time, '%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    # Subtract the random number of days from the base date\n",
    "    random_date = date_obj - timedelta(days=random_days)\n",
    "    \n",
    "    # Subtract the random time from the base date\n",
    "    random_datetime = random_date - timedelta(hours=random_hours, minutes=random_minutes, seconds=random_seconds)\n",
    "    formatted_date = random_datetime.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    return formatted_date\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b57abc1-3054-498e-83d9-d3ea79a8b80e",
   "metadata": {},
   "source": [
    "# day_of_week_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db315213-2e20-42c6-a51e-5842b17cc000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def day_of_week_generator(date_str: str) -> str:\n",
    "    date_object = datetime.strptime(date_str, \"%Y-%m-%d\")\n",
    "    \n",
    "    return date_object.strftime(\"%a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602172a2-6938-4b74-a5cc-bc1df495dec5",
   "metadata": {},
   "source": [
    "# return_date_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91ce972b-e10f-467b-9df5-ee5444862679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_date_list(year: int) -> list:\n",
    "    start_date = str(year) + \"-01-01\"\n",
    "    end_date = str(year) + \"-12-31\"\n",
    "    date_range = pd.date_range(start=start_date, end=end_date)\n",
    "    \n",
    "    return date_range.strftime('%Y-%m-%d').to_list()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f5d7c5-46d6-4064-98ac-3a7a374e4efc",
   "metadata": {},
   "source": [
    "# hike_dates_list_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23230736-4a39-4424-8047-c0a59abb06f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hike_dates_list_generator(input_file: str) -> list:\n",
    "    \"\"\"Creates a list of date(mm-dd) of hike dates\n",
    "    :param input_file: must be in a format of [date1, date2, ...dateN]\n",
    "    :return: list of date(mm-dd)\"\"\"\n",
    "\n",
    "    hike_dates = pd.read_csv(input_file)\n",
    "    return hike_dates['Hike-dates(mm-dd)'].tolist()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35602a9b-175a-43e2-9b80-b38bc9856ecd",
   "metadata": {},
   "source": [
    "# generate_seat_numbers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "faadac05-b22e-4308-ac64-b46674b9905b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_seat_numbers(f_seats: int, f_columns=6) -> list:\n",
    "    '''\n",
    "    Generate f_seats amount of seats like shown\n",
    "    1A 1B 1C 1D 1E 1F 2A 2B 2C 2D 2E 2F .  .\n",
    "\n",
    "    :param f_seats: Total amount of seats in your aeroplane.\n",
    "    :param f_columns: Total amount of columns (A, B, C, ...) default 6\n",
    "    '''\n",
    "    seats = []\n",
    "    seat_letters = list(string.ascii_uppercase[:f_columns])  # A-F columns\n",
    "    row = 1\n",
    "\n",
    "    while len(seats) < f_seats:\n",
    "        for letter in seat_letters:\n",
    "            seats.append(f\"{row}{letter}\")\n",
    "            if len(seats) == f_seats:\n",
    "                break  # Stop once we have 160 seats\n",
    "        row += 1\n",
    "    return seats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d868e7fb-8c5e-4ffc-b445-e75cb169f4a6",
   "metadata": {},
   "source": [
    "# generate_random_order_date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b4638f9-de4e-4afc-b229-7b87f1852372",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_order_date(date_time: str):\n",
    "    \"\"\"Creates a random datetime(randomly selected between 1 - 90 days, time is also random) before the given date\n",
    "    :param: str of format yyyy-mm-dd hh-mm-ss\n",
    "    :return: generates date in format of (yyyy-mm-dd hh-mm-ss) 90 days before the given date_time\"\"\"\n",
    "\n",
    "    random_days = random.randint(1, 90)\n",
    "    random_hours = random.randint(0, 23)\n",
    "    random_minutes = random.randint(0, 59)\n",
    "    random_seconds = random.randint(0, 59)\n",
    "\n",
    "    date_obj = datetime.strptime(date_time, '%Y-%m-%d %H:%M:%S')\n",
    "    # Subtract the random number of days from the base date\n",
    "    random_date = date_obj - timedelta(days=random_days)\n",
    "    # Subtract the random time from the base date\n",
    "    random_datetime = random_date - timedelta(hours=random_hours, minutes=random_minutes, seconds=random_seconds)\n",
    "    formatted_date = random_datetime.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    return formatted_date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65767a9b-40ee-4a4b-981b-e4dd3890c6b4",
   "metadata": {},
   "source": [
    "# route_for_day_of_week()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "937c4845-5cdd-4a6c-bbb8-67001a87bf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_for_day_of_week(day_of_week: str, schedule_day: int) -> tuple:\n",
    "    if day_of_week == 'Sat':\n",
    "        list_routes_of_day = saturday_route_schedule\n",
    "        list_flights_of_day = saturday_flight_schedule\n",
    "        list_departure_time = weekend_departure_times\n",
    "\n",
    "    elif day_of_week == 'Sun':\n",
    "        list_routes_of_day = sunday_route_schedule\n",
    "        list_flights_of_day = sunday_flight_schedule\n",
    "        list_departure_time = weekend_departure_times\n",
    "\n",
    "    else:\n",
    "        list_routes_of_day = route_schedule_data[schedule_day]\n",
    "        list_flights_of_day = flight_schedule_data[schedule_day]\n",
    "        list_departure_time = weekday_departure_times\n",
    "\n",
    "    return list_routes_of_day, list_flights_of_day, list_departure_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e710cd-4b31-4dfe-a781-87bc9dd99fdd",
   "metadata": {},
   "source": [
    "# fake_phone_number()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a07a9c7b-5d76-48df-bcd6-5ed977cdb869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fake_phone_number(f_fake: Faker) -> str:\n",
    "    \"\"\"\n",
    "    Creates a fake phone number with +91 at teh start\n",
    "    :param f_fake: fake\n",
    "    :return: +91 10_digit_ph_no\n",
    "    \"\"\"\n",
    "    return f'+91 {f_fake.msisdn()[3:]}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc20bc88-686f-4fa6-8072-2c6b0484df1d",
   "metadata": {},
   "source": [
    "# return_date_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25930d21-ea2a-4fbb-b062-f0aef4eba9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_date_list(year: int) -> list:\n",
    "    start_date = str(year) + \"-01-01\"\n",
    "    end_date = str(year) + \"-12-31\"\n",
    "    date_range = pd.date_range(start=start_date, end=end_date)\n",
    "    return date_range.strftime('%Y-%m-%d').to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9df2a5-c810-4f32-9b14-d2302c540e9a",
   "metadata": {},
   "source": [
    "# orders_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f919b4f-3192-4cf6-83df-304d1b26d07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def orders_generator(customer_limit: int,\n",
    "                     year: int,\n",
    "                     output_file: str,\n",
    "                     schedule_output_file: str,\n",
    "                     customer_start: int = 0,\n",
    "                     orders_id: int = 1) -> tuple:\n",
    "    \"\"\"\n",
    "    Creates a csv file with format\n",
    "    (order_id,customer_id,route_id,flight_id,order_date,departure_time,base_price,seat_no)\\n\n",
    "\n",
    "    :param schedule_output_file: creates a new file with date and the route_id based on the incomplete files\n",
    "    :param customer_limit: selects a random number from (1, customer_limit) for the customer_id\n",
    "    :param year: generates a list of dates of the given year and uses the year to generate a ticket estimate\n",
    "    :param output_file: file to print the data\n",
    "    :return: orders_id\n",
    "    \"\"\"\n",
    "    \n",
    "    schedule_list = []\n",
    "    orders_list = []\n",
    "\n",
    "    # date_count needs to be incremented by 1 as my schedule file has monday to friday \n",
    "    date_count = 0\n",
    "    if year == 2019:\n",
    "        date_count = 1\n",
    "    elif year == 2020:\n",
    "        date_count = 2\n",
    "    elif year == 2021:\n",
    "        date_count = 3\n",
    "\n",
    "\n",
    "    # orders_id takes on the last order_id from the previous iteration as to maintain contiguous primary key\n",
    "    order_id = orders_id\n",
    "    schedule_id = 1\n",
    "\n",
    "    # returns the list of dates in that year\n",
    "    list_of_dates = return_date_list(year)\n",
    "\n",
    "    # Now iterating through the newly generated list of dates\n",
    "    for date in list_of_dates:\n",
    "\n",
    "        # in my routes schedule file I have 59 routes when we reach the last row i wanted to get the row counter back to \n",
    "        # the first row thats y date_count = 0 when it hits 60\n",
    "        if date_count == 60: \n",
    "            date_count = 0\n",
    "\n",
    "        # Get a day name for each iteration\n",
    "        day_name = day_of_week_generator(date)\n",
    "\n",
    "        # returns the routes, flights and the departure dates for that day\n",
    "        routes_of_day, flights_of_day, departure_time_list = route_for_day_of_week(day_name, date_count)\n",
    "        number_of_routes = len(routes_of_day)\n",
    "\n",
    "        # Now iterate through the routes present in the current day\n",
    "        for route in range(number_of_routes):\n",
    "            # route id and flight id will be the current route\n",
    "            route_id = routes_of_day[route]\n",
    "            f_flight_id = flights_of_day[route]\n",
    "            # Creating Departure date datetime\n",
    "            departure_date = date + \" \" + departure_time_list[route]\n",
    "\n",
    "            # Getting the base price \n",
    "            base_price = float(all_routes_dict[route_id][-1])\n",
    "\n",
    "            # Year wise discount or increase based on personal preference\n",
    "            if year == 2018:\n",
    "                base_price -= base_price * 0.1\n",
    "            elif year == 2019:\n",
    "                base_price += base_price * 0.2\n",
    "\n",
    "            # Calculate the amount of seats present in the current flight\n",
    "            max_tickets = int(aircraft_dict[f_flight_id])\n",
    "            \n",
    "            ticket_estimate = ticket_estimator(date, hike_dates, max_tickets, year)\n",
    "            total_seats = generate_seat_numbers(max_tickets)\n",
    "\n",
    "            # Create schedules file with this list\n",
    "            schedules_row = [schedule_id, date, route_id, f_flight_id, departure_time_list[route]]\n",
    "            schedule_list.append(schedules_row)\n",
    "\n",
    "            # Generate order dates for all the ticktes before the departure date ans then sort it \n",
    "            new_order_dates = [generate_random_order_date(departure_date) for _ in range(ticket_estimate)]\n",
    "            new_order_dates.sort()\n",
    "            \n",
    "            schedule_id += 1\n",
    "\n",
    "            for seat in range(ticket_estimate):\n",
    "                # Select a random seat and the earliest order date\n",
    "                random_seat = random.choice(total_seats)\n",
    "                order_date = new_order_dates[seat]\n",
    "\n",
    "                # Select a random customer from these limit to mimic a customer\n",
    "                start = customer_start + 1\n",
    "                end = customer_limit + customer_start\n",
    "                customer_id = random.randint(start, end)\n",
    "                \n",
    "                orders_row = [order_id, customer_id, route_id, f_flight_id, order_date, departure_date, base_price, random_seat]\n",
    "                orders_list.append(orders_row)\n",
    "\n",
    "                # once the seat is added to the list remove the seat from the list of seats \n",
    "                total_seats.remove(random_seat)\n",
    "                \n",
    "                order_id += 1\n",
    "                \n",
    "        if day_name not in (\"Sat\", \"Sun\"):\n",
    "            date_count += 1\n",
    "\n",
    "    df_schedules = pd.DataFrame(schedule_list, \n",
    "                                columns=['schedule_id', 'date', 'route_id', 'flight_id', 'departure_time'],\n",
    "                                index=range(1, len(schedule_list) + 1))\n",
    "    df_schedules.to_csv(schedule_output_file, index=False)\n",
    "    del schedule_list, df_schedules\n",
    "\n",
    "    df_orders = pd.DataFrame(orders_list, \n",
    "                            columns=['order_id', 'customer_id', 'route_id', 'flight_id', 'order_date', 'departure_time', 'base_price', 'seat_no'],\n",
    "                            index=range(1, len(orders_list) + 1))\n",
    "    df_orders.to_csv(output_file, index=False)\n",
    "    del orders_list, df_orders\n",
    "\n",
    "    # return the last order id and the total customer id to facilitate the next iteration\n",
    "    return order_id, end\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a3bf6e-4ecd-4a59-995f-528303e79002",
   "metadata": {},
   "source": [
    "# cancellations_updator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d0b4ff1-8cf2-4212-b2ef-17a5fc730756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cancellations_updator(f_input_file: str, f_output_file: str, cancellation_percentage: int,\n",
    "                          customer_limit: int, customer_start: int = 0, f_id: int = 1) -> tuple:\n",
    "    \"\"\"\n",
    "    updates the input file with a cancellations column based on the percentage given with `cancellation_percentage` of\n",
    "    records will show \"Cancelled\" and creates an output file with all the \"Cancelled\" orders(no index in the output_file)\n",
    "    :param customer_limit:\n",
    "    :param f_input_file: any `csv` file\n",
    "    :param f_output_file: any file\n",
    "    :param cancellation_percentage: percentage of records to show \"Cancelled\" at the end\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    # Cancelling some orders randomly\n",
    "    df = pd.read_csv(f_input_file)\n",
    "    total_records = len(df)\n",
    "    cancellations_entries = int(total_records * (cancellation_percentage / 100))\n",
    "    no_indices = random.sample(range(total_records), cancellations_entries)\n",
    "    df['cancellations'] = \"Confirmed\"\n",
    "    df.loc[no_indices, 'cancellations'] = 'Cancelled'\n",
    "    df.to_csv('temporary_file.csv', index=False)\n",
    "\n",
    "    new_order_id = f_id\n",
    "    with (open('temporary_file.csv', encoding='utf-8', newline='') as orders_c_file,\n",
    "          open(f_input_file, 'w', newline='') as orders_final_file,\n",
    "          open(f_output_file, 'w', newline='') as cancellations_file):\n",
    "        orders_c_file.readline().strip('\\r\\n').split(',')\n",
    "        reader = csv.reader(orders_c_file)\n",
    "        print('order_id,customer_id,route_id,flight_id,order_date,departure_date,base_price,seat_no,Confirmation',\n",
    "              file=orders_final_file)\n",
    "        print('order_id,cancellation_date',\n",
    "              file=cancellations_file)\n",
    "        for row in reader:\n",
    "            order_id, customer_id, route_id, flight_id, order_date, departure_date, base_price, seat_no, cancellations = row\n",
    "            \n",
    "            if cancellations == 'Cancelled':\n",
    "                start = customer_start + 1\n",
    "                end = customer_limit + customer_start\n",
    "                new_customer_id = random.randint(start, end)\n",
    "\n",
    "                # get a cancellation date which is after the confirmed date and before the departure date\n",
    "                cancellation_date = generate_random_datetime(order_date, departure_date)\n",
    "                cancellation_date_str = cancellation_date.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                new_order_date = generate_random_datetime(cancellation_date_str, departure_date)\n",
    "                                                         \n",
    "                print(f'{new_order_id},{customer_id},{route_id},{flight_id},{order_date},{departure_date},{base_price},{seat_no},{cancellations}', \n",
    "                  file=orders_final_file)\n",
    "                                                        \n",
    "                print(\n",
    "                    f'{new_order_id},{cancellation_date}',\n",
    "                        file=cancellations_file)\n",
    "                new_order_id += 1\n",
    "                \n",
    "                print(\n",
    "                    f'{new_order_id},{new_customer_id},{route_id},{flight_id},{new_order_date},{departure_date},{base_price},{seat_no},Confirmed',\n",
    "                    file=orders_final_file)\n",
    "                                                          \n",
    "                new_order_id += 1\n",
    "                \n",
    "            else:    \n",
    "                print(f'{new_order_id},{customer_id},{route_id},{flight_id},{order_date},{departure_date},{base_price},{seat_no},{cancellations}', \n",
    "                      file=orders_final_file)\n",
    "                new_order_id += 1\n",
    "    os.remove('temporary_file.csv')\n",
    "\n",
    "    return new_order_id, end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a65865-673c-4bfd-8f23-f0c8da33d0d1",
   "metadata": {},
   "source": [
    "# sort_by_order_date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b7e9bed-92fc-4be8-b493-5f5626889813",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_order_date(input_file: str) -> None:\n",
    "    df = pd.read_csv(input_file)\n",
    "    df = df.sort_values(by='order_date')\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df.index = df.index + 1\n",
    "    df = df.drop(columns=['order_id'])\n",
    "    df.to_csv(input_file, index=True, index_label='order_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18143068-1624-4272-9e38-28c6ad674f44",
   "metadata": {},
   "source": [
    "# customer_membership_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87d59333-18ba-4d1f-b3c5-6f77ffcd5adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def customer_membership_status(input_file: str, percentage: int) -> None:\n",
    "    \"\"\"\n",
    "    Updates the input_file with membership status based on the percentage given\n",
    "    :param input_file: customers_file\n",
    "    :param percentage: percentage of record to show 'Yes' in the membership column\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(input_file)\n",
    "    num_records = len(df)\n",
    "    sample_size = int((percentage / 100) * num_records)\n",
    "    yes_indices = random.sample(range(num_records), sample_size)\n",
    "    df['membership'] = 'NO'\n",
    "    df.loc[yes_indices, 'membership'] = 'YES'\n",
    "    df.to_csv(input_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584bd986-9f31-408f-9415-c1d5a60eda4f",
   "metadata": {},
   "source": [
    "# generate_random_age()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f68cccc9-cc90-43a1-8c4f-447191fe662e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_age():\n",
    "    # Define the age ranges and their corresponding weights\n",
    "    age_ranges = [(25, 50), (12, 80)]\n",
    "    weights = [0.8, 0.2]  # 80% chance for (25, 50), 20% for (12, 80)\n",
    "    \n",
    "    # Choose a range based on the defined weights\n",
    "    chosen_range = random.choices(age_ranges, weights, k=1)[0]\n",
    "    \n",
    "    # Generate a random age within the chosen range\n",
    "    random_age = random.randint(chosen_range[0], chosen_range[1])\n",
    "    return random_age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee4a20c-cfb7-4004-8c95-4b347d1e6586",
   "metadata": {},
   "source": [
    "# customer_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77704fa7-996d-46c2-83a3-5fa6483e0dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def customer_generator(input_file: str, customer_limit: int, fc_id: int = 1) -> int:\n",
    "    \"\"\"Generates customer_id, f_name, l_name, ph_no and email using faker for the desired customer_limit\n",
    "    Don't use a large number as it might take a long time\n",
    "    :param input_file: file to generate the values into\n",
    "    :param customer_limit: amount of records to be printed in that file\n",
    "    :return: None\"\"\"\n",
    "    with open(input_file, 'w', newline='') as customer_file:\n",
    "        c_id = fc_id\n",
    "        print(\"c_id,name,gender,age,ph_no,email\", file=customer_file)\n",
    "        for _ in range(customer_limit):\n",
    "            genders = ['Male', 'Female']\n",
    "            gender = fake.random_element(genders)\n",
    "            name = fake.name_male() if gender == \"Male\" else fake.name_female()\n",
    "            ph_no = fake_phone_number(fake)\n",
    "            email = name + ph_no[-3:] + \"@gmail.com\"\n",
    "            age = generate_random_age()\n",
    "            print(f\"{c_id},{name},{gender},{age},{ph_no},{email}\", file=customer_file)\n",
    "            c_id += 1\n",
    "    return c_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9676d1cf-318b-4d7f-a616-6fc7d2d10a9f",
   "metadata": {},
   "source": [
    "# generate_random_datetime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c00b0b5-4d85-4e45-bf45-267b09696a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_datetime(start_date: str, end_date: str):\n",
    "    \"\"\"\n",
    "    Generates a random datetime value between the start_date and end_date\n",
    "    :param start_date: date_time str\n",
    "    :param end_date: date_time str\n",
    "    :return: Return a datetime that is between the start_date and end_date\n",
    "    \"\"\"\n",
    "    start_dt = datetime.strptime(start_date, '%Y-%m-%d %H:%M:%S')\n",
    "    end_dt = datetime.strptime(end_date, '%Y-%m-%d %H:%M:%S')\n",
    "    time_difference = (end_dt - start_dt).total_seconds()\n",
    "    random_seconds = random.randint(0, int(time_difference))\n",
    "    return start_dt + timedelta(seconds=random_seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe215836-bd07-4fa2-885d-05d3533e2ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_route_schedule = pd.read_csv(\"routes_schedule_complete.csv\", header=None)\n",
    "route_schedule_data = df_route_schedule.to_records(False).tolist()\n",
    "saturday_route_schedule = [1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "sunday_route_schedule = [1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "\n",
    "df_flight_schedule = pd.read_csv(\"flight_schedule_complete.csv\", header=None)\n",
    "flight_schedule_data = df_flight_schedule.to_records(False).tolist()\n",
    "saturday_flight_schedule = [1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "sunday_flight_schedule = [1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "\n",
    "weekday_departure_times = ['06:00:00', '07:30:00', '08:00:00', '09:00:00', '10:30:00', '11:00:00', '12:00:00',\n",
    "                           '13:00:00', '14:30:00', '15:30:00', '17:30:00', '18:00:00', '18:30:00', '19:30:00',\n",
    "                           '21:30:00']\n",
    "weekend_departure_times = ['06:00:00', '06:30:00', '07:00:00', '07:30:00', '08:00:00', '09:00:00', '10:30:00',\n",
    "                           '11:00:00', '12:00:00', '13:00:00', '14:30:00', '15:30:00', '17:30:00', '18:00:00',\n",
    "                           '18:30:00', '19:30:00', '20:30:00', '21:30:00']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e48d5cb-352d-4193-ba04-be337090d847",
   "metadata": {},
   "source": [
    "# Generating job roles and both ground and air staffs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a672f45-3ea6-4ed2-9776-427761172cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "aircraft_file = pd.read_csv(\"DreamAir_Aircraft.csv\")\n",
    "flight_id_list = aircraft_file[\"aircraft_ID\"].tolist()\n",
    "\n",
    "with (open(\"DreamAir_Job_Roles.csv\", encoding='utf-8', newline='') as job_roles_file,\n",
    "      open(\"DreamAir_On_Flight_Staffs.csv\", 'w', newline='') as on_flights_staffs,\n",
    "      open(\"DreamAir_Ground_Staffs.csv\", 'w', newline='') as off_Flight_staffs):\n",
    "    job_roles_file.readline().strip('\\r\\n').split(',')\n",
    "    print(\"ID,job_roles_id,name,gender,ph_no,email\", file=off_Flight_staffs)\n",
    "    print(\"ID,flight_id,job_role_id,name,gender,ph_no,email\", file=on_flights_staffs)\n",
    "\n",
    "    jobs_reader = csv.reader(job_roles_file)\n",
    "    on_count = 1\n",
    "    off_count = 1\n",
    "    for job_role_row in jobs_reader:\n",
    "        if job_role_row[-1] == 'on':\n",
    "            for flight_id_no in flight_id_list:\n",
    "                for i in range(int(job_role_row[-2])):\n",
    "                    genders = ['Male', 'Female', 'Male']\n",
    "                    gender = fake.random_element(genders)\n",
    "                    name = fake.name_male() if gender == \"Male\" else fake.name_female()\n",
    "                    e_ph_no = fake_phone_number(fake)\n",
    "                    e_email = name + e_ph_no[-3:] + \"@gmail.com\"\n",
    "                    print(f\"{on_count},{flight_id_no},{job_role_row[0]},{name},{gender},{e_ph_no},{e_email}\", file=on_flights_staffs)\n",
    "                    on_count += 1\n",
    "        else:\n",
    "            employee_count = int(job_role_row[-2])\n",
    "            for i in range(employee_count):\n",
    "                genders = ['Male', 'Female', 'Male']\n",
    "                gender = fake.random_element(genders)\n",
    "                name = fake.name_male() if gender == \"Male\" else fake.name_female()\n",
    "                e_ph_no = fake_phone_number(fake)\n",
    "                e_email = name + e_ph_no[-3:] + \"@gmail.com\"\n",
    "                print(f\"{off_count},{job_role_row[0]},{name},{gender},{e_ph_no},{e_email}\", file=off_Flight_staffs)\n",
    "                off_count += 1\n",
    "\n",
    "job_roles_df = pd.read_csv(\"DreamAir_Job_Roles.csv\")\n",
    "job_roles_df.drop(\"count\", inplace=True, axis=1)\n",
    "job_roles_df.drop(\"on/off\", inplace=True, axis=1)\n",
    "job_roles_df.to_csv(\"DreamAir_Job_Roles.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f2971b-265f-41a3-bb74-f5e11109e8c2",
   "metadata": {},
   "source": [
    "# Hike dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a4bcb6d2-c45e-4975-93a0-0267398c36ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "hike_dates = hike_dates_list_generator(\"Hike_Dates.csv\")\n",
    "create_routes(\"DreamAir_Routes.csv\", da_airport_coordinates, da_aircraft_speed, da_price_multiplier, 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3629c8aa-0015-4db1-beae-430f6f03da7f",
   "metadata": {},
   "source": [
    "# Creating necessary dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "21c42924-bed4-42ac-b83e-bb584b28e69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_routes_dict = routes_dict_generator(\"DreamAir_Routes.csv\")\n",
    "aircraft_dict = aircraft_dict_generator(\"DreamAir_Aircraft.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b59c47-ca32-44bc-83cb-0b7a8bdb3b38",
   "metadata": {},
   "source": [
    "# Creating seat info csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f148b1d-f9ca-4667-8782-2ba419f63f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"DreamAir_Seat_Info.csv\", 'w', newline='') as seats_file:\n",
    "    ID = 1\n",
    "    for flightId, value in aircraft_dict.items():\n",
    "        max_seats = generate_seat_numbers(int(value))\n",
    "        for seat_num in max_seats:\n",
    "            print(f'{ID},{flightId},{seat_num}', file=seats_file)\n",
    "            ID += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792558b3-cc12-4d2b-84dc-4994aeee2d6c",
   "metadata": {},
   "source": [
    "# Customer generator and membership updator \n",
    "2018 memberships 26 %\n",
    "\n",
    "2019 memberships 48 %\n",
    "\n",
    "2020 memberships 36 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "055ebfbd-4ae6-48ce-acdf-26f4b72c6c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_2019 = customer_generator(\"DreamAir_2018_Customers.csv\", 275236)\n",
    "customer_membership_status(\"DreamAir_2018_Customers.csv\", 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc992f7e-081e-4b16-8293-9a7af69a6e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_2020 = customer_generator(\"DreamAir_2019_Customers.csv\", 396452, id_2019)\n",
    "customer_membership_status(\"DreamAir_2019_Customers.csv\", 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a89e50d4-8790-43ad-99ce-200cc91285fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_2021 = customer_generator(\"DreamAir_2020_Customers.csv\", 351426, id_2020)\n",
    "customer_membership_status(\"DreamAir_2020_Customers.csv\", 36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8d2b1c25-8b52-410e-9708-8216890fbb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_generator(\"DreamAir_2021_Customers.csv\", 412536, id_2021)\n",
    "customer_membership_status(\"DreamAir_2021_Customers.csv\", 51)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19195e0a-b743-4416-bf1b-c3556fc7fa15",
   "metadata": {},
   "source": [
    "# Generating Orders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ba03e283-75af-4293-8521-1a0ad6a0d8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_end_2018, customer_end_2018 = orders_generator(275236, 2018, \"DreamAir_2018_Orders.csv\", \"DreamAir_2018_Schedule.csv\", 0, 1)\n",
    "orders_end_2018_c, customer_end_2018_c = cancellations_updator(\"DreamAir_2018_Orders.csv\", \"DreamAir_2018_Cancellations.csv\", 5, 275236, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4ce489de-da67-4cda-b3b6-bb898d9ad57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_end_2019, customer_end_2019 = orders_generator(396452, 2019, \"DreamAir_2019_Orders.csv\",\n",
    "                 \"DreamAir_2019_Schedule.csv\", customer_end_2018, orders_end_2018)\n",
    "orders_end_2019_c, customer_end_2019_c = cancellations_updator(\"DreamAir_2019_Orders.csv\", \"DreamAir_2019_Cancellations.csv\",\n",
    "                      8, 396452, customer_end_2018_c, orders_end_2018_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "54e7ac47-6f23-40a6-8859-05eae9bea4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_end_2020, customer_end_2020 = orders_generator(351426, 2020, \"DreamAir_2020_Orders.csv\",\n",
    "                 \"DreamAir_2020_Schedule.csv\", customer_end_2019, orders_end_2019)\n",
    "orders_end_2020_c, customer_end_2020_c = cancellations_updator(\"DreamAir_2020_Orders.csv\", \"DreamAir_2020_Cancellations.csv\",\n",
    "                      10, 351426, customer_end_2019_c, orders_end_2019_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e0930cd4-9ba6-471a-bf36-6ec3a664f3ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3802731, 1374540)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders_generator(351426, 2021, \"DreamAir_2021_Orders.csv\",\n",
    "                 \"DreamAir_2021_Schedule.csv\", customer_end_2020, orders_end_2020)\n",
    "cancellations_updator(\"DreamAir_2021_Orders.csv\", \"DreamAir_2021_Cancellations.csv\",\n",
    "                      6, 351426, customer_end_2020_c, orders_end_2020_c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
